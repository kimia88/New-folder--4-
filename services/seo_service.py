import json
import logging
import os
import re
import time
from datetime import datetime
from typing import List, Dict, Any
from difflib import SequenceMatcher

from services.seo_title_evaluator import SEOTitleEvaluator
from services.llm_service import QService  # ÙØ±Ø¶ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ… Ù‡Ù…ÛŒÙ† Ú©Ù„Ø§Ø³ QService Ø§Ø³Øª


class SEOService:
    def __init__(self, db, q_service: QService, min_score=8.5, retries=8, delay=4.0, max_backoff=60.0):
        self.db = db
        self.q_service = q_service
        self.min_score = min_score
        self.retries = retries
        self.delay = delay
        self.max_backoff = max_backoff
        self.evaluator = SEOTitleEvaluator()

        logging.basicConfig(level=logging.INFO, format="%(asctime)s | %(levelname)s | %(message)s")

    def extract_focus_keyword(self, title: str) -> str:
        stopwords = {"the", "of", "and", "a", "an", "to", "in", "on", "for", "with", "at", "by",
                     "Ø±Ø§", "Ùˆ", "Ú©Ù‡", "Ø§Ø²", "Ø§ÛŒÙ†", "Ø¨Ø§", "Ø¨Ù‡"}
        words = [w.lower() for w in re.findall(r'\w+', title) if w.lower() not in stopwords]
        return " ".join(words[:3]) if words else title.strip().lower()

    def generate_title_for_all(self):
        logging.info("ðŸš€ Ø´Ø±ÙˆØ¹ ÙØ±Ø¢ÛŒÙ†Ø¯ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¹Ù†Ø§ÙˆÛŒÙ† Ø¨Ø±Ø§ÛŒ Ø³Ø¦Ùˆ...")
        contents = self.db.get_all_purecontents()
        results = []

        for content_id, title, *_rest, lang_id in contents:
            if not title or not title.strip():
                logging.info(f"âŒ Skipped empty title for content_id {content_id}")
                continue

            keyword = self.extract_focus_keyword(title)
            original_score = self.evaluator.evaluate_title(title, keyword)
            best_title, best_score = title, original_score

            candidates = [{"title": title, "score": original_score}]
            backoff = self.delay

            for attempt in range(1, self.retries + 1):
                prompt = self._build_prompt(best_title, lang_id, best_score, attempt > 2 or best_score < self.min_score / 2)

                try:
                    response_initial = self.q_service.send_request(prompt)
                    if "error" in response_initial:
                        raise ValueError("Error in sending request")

                    raw_response = self.q_service.get_response()
                    if not raw_response or "âš ï¸" in raw_response:
                        raise ValueError("No valid response from model")

                    data = self._parse_response(raw_response)
                    candidate = data.get("optimized_title", "").strip()

                    if not candidate:
                        raise ValueError("Empty optimized_title")

                    if self._looks_gibberish(candidate):
                        raise ValueError("Gibberish detected")

                    score = self.evaluator.evaluate_title(candidate, keyword)
                    similarity = self._similarity_ratio(best_title, candidate)

                    candidates.append({"title": candidate, "score": score})

                    if score > best_score and similarity < 0.8:
                        best_title = candidate
                        best_score = score
                        backoff = self.delay  # reset backoff after improvement

                except (ValueError, json.JSONDecodeError):
                    pass  # Ø®Ø·Ø§Ù‡Ø§ Ø±Ùˆ Ù†Ø§Ø¯ÛŒØ¯Ù‡ Ù…ÛŒâ€ŒÚ¯ÛŒØ±ÛŒÙ… Ùˆ ØªÙ„Ø§Ø´ Ø¨Ø¹Ø¯ÛŒ Ø±Ùˆ Ù…ÛŒâ€ŒØ²Ù†ÛŒÙ…
                except Exception:
                    pass

                time.sleep(backoff)
                backoff = min(backoff * 2, self.max_backoff)

            if best_score > original_score and best_title != title:
                self._update_title_in_database(content_id, best_title, best_score)
                logging.info(
                    f"âœ… content_id: {content_id} | original_score: {original_score:.2f} | optimized_score: {best_score:.2f}\n"
                    f"    original_title: {title}\n"
                    f"    optimized_title: {best_title}"
                )
            else:
                logging.info(f"â„¹ï¸ content_id: {content_id} | No meaningful improvement")

            results.append({
                "content_id": content_id,
                "original_title": title,
                "optimized_title": best_title,
                "seo_score": best_score,
                "candidates": candidates
            })

        self._save_results(results)
        logging.info("ðŸŽ‰ ÙØ±Ø¢ÛŒÙ†Ø¯ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¹Ù†Ø§ÙˆÛŒÙ† Ø¨Ù‡ Ù¾Ø§ÛŒØ§Ù† Ø±Ø³ÛŒØ¯")

    def _parse_response(self, raw: str) -> Dict[str, Any]:
        json_matches = re.findall(r"\{.*?\}", raw, re.DOTALL)
        if not json_matches:
            raise ValueError("JSON not found in response.")
        try:
            return json.loads(json_matches[0])
        except json.JSONDecodeError as e:
            raise ValueError(f"Invalid JSON in response: {e}")

    def _build_prompt(self, title: str, lang_id: int, last_score: float, emphasize_change: bool) -> str:
        if lang_id == 1:  # Persian
            prompt = (
                "Ø¹Ù†ÙˆØ§Ù† Ø²ÛŒØ± Ø±Ø§ Ø¨Ù‡ ØµÙˆØ±Øª Ø¨Ù‡ÛŒÙ†Ù‡ Ø¨Ø±Ø§ÛŒ Ø³Ø¦Ùˆ Ø¨Ø§Ø²Ù†ÙˆÛŒØ³ÛŒ Ú©Ù†. Ø¹Ù†ÙˆØ§Ù† Ø¨Ø§ÛŒØ¯ Ù…Ø¹Ù†ÛŒâ€ŒØ¯Ø§Ø±ØŒ Ø¬Ø°Ø§Ø¨ØŒ Ø®Ù„Ø§ØµÙ‡ØŒ Ùˆ Ø´Ø§Ù…Ù„ Ú©Ù„ÛŒØ¯ÙˆØ§Ú˜Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ù‡Ù… Ø¨Ø§Ø´Ø¯. "
                "ÙÙ‚Ø· Ø®Ø±ÙˆØ¬ÛŒ JSON Ù…Ø§Ù†Ù†Ø¯ Ø²ÛŒØ± Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†:\n"
                "{\n"
                "  \"original_title\": \"...\",\n"
                "  \"optimized_title\": \"...\",\n"
                "  \"score\": Ø¹Ø¯Ø¯ Ø¨ÛŒÙ† Û° ØªØ§ Û±Û°\n"
                "}\n\n"
                f"Ø¹Ù†ÙˆØ§Ù†:\n{title}"
            )
            if emphasize_change:
                prompt += "\nâ— Ù„Ø·ÙØ§Ù‹ Ù†Ø³Ø®Ù‡â€ŒØ§ÛŒ Ú©Ø§Ù…Ù„Ø§Ù‹ Ø¬Ø¯ÛŒØ¯ Ùˆ Ø¨Ø§ Ø³Ø¦Ùˆ Ù‚ÙˆÛŒâ€ŒØªØ± Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ø¨Ø¯Ù‡."
        else:  # English
            prompt = (
                "Rewrite the following title to be SEO optimized. Make it clear, attractive, and keyword-rich. "
                "Respond ONLY with a JSON like:\n"
                "{\n"
                "  \"original_title\": \"...\",\n"
                "  \"optimized_title\": \"...\",\n"
                "  \"score\": number between 0 and 10\n"
                "}\n\n"
                f"Title:\n{title}"
            )
            if emphasize_change:
                prompt += "\nâ— Please provide a much better SEO version."

        return prompt

    def _save_results(self, results: List[Dict[str, Any]]):
        ts = datetime.now().strftime("%Y%m%d_%H%M%S")
        path = f"seo_output/seo_results_{ts}.json"
        os.makedirs("seo_output", exist_ok=True)
        try:
            with open(path, "w", encoding="utf-8") as f:
                json.dump(results, f, ensure_ascii=False, indent=2)
            logging.info(f"ðŸ“ Results saved: {path}")
        except Exception as e:
            logging.error(f"âŒ Failed to save results: {e}")

    def _update_title_in_database(self, content_id: int, optimized_title: str, seo_score: float):
        try:
            self.db.update_pure_content(content_id, optimized_title)
            logging.info(f"âœ… Updated content_id {content_id} with: {optimized_title} (Score: {seo_score:.2f})")
        except Exception as e:
            logging.error(f"âŒ DB update error for content_id {content_id}: {e}")

    def _similarity_ratio(self, a: str, b: str) -> float:
        return SequenceMatcher(None, a, b).ratio()

    def _looks_gibberish(self, title: str) -> bool:
        words = re.findall(r'\w+', title)
        if not words:
            return True
        gibberish_count = 0
        for w in words:
            if len(w) > 20 or not re.search(r'[a-zA-Z0-9\u0600-\u06FF]', w):
                gibberish_count += 1
        return gibberish_count / len(words) > 0.3
